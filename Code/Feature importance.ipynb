{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1078413b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Promedio del error absoluto: 0.0  Porcentaje.\n",
      "Precision: nan %.\n",
      "Variable: Command_id           Importance: 0.9\n",
      "Variable: PID                  Importance: 0.08\n",
      "Variable: Path_id              Importance: 0.02\n",
      "Variable: Detail_id            Importance: 0.01\n",
      "Variable: Operation_id         Importance: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pr14p\\AppData\\Local\\Temp\\ipykernel_9400\\1077264596.py:62: RuntimeWarning: divide by zero encountered in true_divide\n",
      "  mape = 100 * (errors / test_labels)\n",
      "C:\\Users\\pr14p\\AppData\\Local\\Temp\\ipykernel_9400\\1077264596.py:62: RuntimeWarning: invalid value encountered in true_divide\n",
      "  mape = 100 * (errors / test_labels)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import random\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import sklearn\n",
    "from scipy import stats\n",
    "from sklearn.cluster import KMeans\n",
    "import seaborn as sns\n",
    "# Using Skicit-learn to split data into training and testing sets\n",
    "from sklearn.model_selection import train_test_split\n",
    "# Import the model we are using\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "import os\n",
    "\n",
    "features = pd.read_csv(r'C:\\Users\\pr14p\\Desktop\\Final\\All 50-50\\all_data_with_inique_value.csv')\n",
    "\n",
    "# Labels are the values we want to predict\n",
    "labels = np.array(features['Class'])\n",
    "# Remove the labels from the features\n",
    "# axis 1 refers to the columns\n",
    "features= features.drop('Time of Day', axis = 1)\n",
    "features= features.drop('Class', axis = 1)\n",
    "features= features.drop('Operation', axis = 1)\n",
    "features= features.drop('Path', axis = 1)\n",
    "features= features.drop('Detail', axis = 1)\n",
    "features= features.drop('Process Name', axis = 1)\n",
    "features= features.drop('Command Line', axis = 1)\n",
    "\n",
    "# Saving feature names for later use\n",
    "feature_list = list(features.columns)\n",
    "\n",
    "\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "train_features, test_features, train_labels, test_labels = train_test_split(features, labels, test_size = 0.30, random_state = 42)\n",
    "\n",
    "\n",
    "\n",
    "#baseline_preds = test_features[:, feature_list.index('Violent crime')]\n",
    "    # Baseline errors, and display average baseline error\n",
    "#baseline_errors = abs(baseline_preds - test_labels)\n",
    "#print('Error: ', round(np.mean(baseline_errors), 2))\n",
    "\n",
    "# Instantiate model with 1000 decision trees\n",
    "rf = RandomForestRegressor(n_estimators = 1000, random_state = 42)\n",
    "# Train the model on training data\n",
    "rf.fit(train_features, train_labels);\n",
    "\n",
    "# Use the forest's predict method on the test data\n",
    "predictions = rf.predict(test_features)\n",
    "# Calculate the absolute errors\n",
    "errors = abs(predictions - test_labels)\n",
    "# Print out the mean absolute error (mae)\n",
    "print('Promedio del error absoluto:', round(np.mean(errors), 2), ' Porcentaje.')\n",
    "\n",
    "\n",
    "# Calculate mean absolute percentage error (MAPE)\n",
    "mape = 100 * (errors / test_labels)\n",
    "# Calculate and display accuracy\n",
    "accuracy = 100 - np.mean(mape)\n",
    "print('Precision:', round(accuracy, 2), '%.')\n",
    "\n",
    "# Get numerical feature importances\n",
    "importances = list(rf.feature_importances_)\n",
    "# List of tuples with variable and importance\n",
    "feature_importances = [(feature, round(importance, 2)) for feature, importance in zip(feature_list, importances)]\n",
    "# Sort the feature importances by most important first\n",
    "feature_importances = sorted(feature_importances, key = lambda x: x[1], reverse = True)\n",
    "# Print out the feature and importances \n",
    "[print('Variable: {:20} Importance: {}'.format(*pair)) for pair in feature_importances];\n",
    "\n",
    "# Import tools needed for visualization\n",
    "from sklearn.tree import export_graphviz\n",
    "import pydot\n",
    "# Pull out one tree from the forest\n",
    "tree = rf.estimators_[5]\n",
    "# Import tools needed for visualization\n",
    "from sklearn.tree import export_graphviz\n",
    "import pydot\n",
    "# Pull out one tree from the forest\n",
    "tree = rf.estimators_[5]\n",
    "# Export the image to a dot file\n",
    "export_graphviz(tree, out_file = 'tree.dot', feature_names = feature_list, rounded = True, precision = 1)\n",
    "# Use dot file to create a graph\n",
    "(graph, ) = pydot.graph_from_dot_file('tree.dot')\n",
    "# Write graph to a png file\n",
    "graph.write_png('tree.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fae73b9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
